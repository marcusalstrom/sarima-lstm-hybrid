{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/sarima_residuals.csv\")\n",
    "residuals = df.values\n",
    "plt.plot(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(residuals) * 0.67)\n",
    "test_size = len(residuals) - train_size\n",
    "train, test = residuals[:train_size], residuals[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), :]  #get look_back sequences\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0]) #get the target after look_back sequences\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 30\n",
    "trainX, trainY = create_dataset(train_scaled, look_back)\n",
    "testX, testY = create_dataset(test_scaled, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"trainX Shape: \",trainX.shape) #[samples, time steps, features]\n",
    "print(\"trainY Shape: \",trainY.shape)\n",
    "\n",
    "print(\"testX Shape: \",testX.shape) #[samples, time steps, features]\n",
    "print(\"testY Shape: \",testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            hp.Int(\"input_unit\", min_value=32, max_value=128, step=32),\n",
    "            return_sequences=True,\n",
    "            input_shape=(5, 1),\n",
    "        )\n",
    "    )\n",
    "    if hp.Boolean(\"add_middle_lstm\"):\n",
    "        model.add(\n",
    "            LSTM(\n",
    "                hp.Int(\"middle_units\", min_value=32, max_value=128, step=32),\n",
    "                return_sequences=True,\n",
    "            )\n",
    "        )\n",
    "        # model.add(\n",
    "        #     Dropout(hp.Float(\"middle_dropout\", min_value=0, max_value=0.5, step=0.1))\n",
    "        # )\n",
    "    # for i in range(hp.Int('n_layers', 0, 2)):\n",
    "    #     model.add(LSTM(hp.Int(f'lstm_{i}_units',min_value=32,max_value=128,step=32),return_sequences=True))\n",
    "    #     model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n",
    "    model.add(LSTM(hp.Int(f\"last_units\", min_value=32, max_value=128, step=32)))\n",
    "    # model.add(Dropout(hp.Float(\"last_dropout\", min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform and reshape predictions\n",
    "def inverse_transform_and_reshape(predictions, scaler, shape):\n",
    "    predictions_copies = np.repeat(predictions, shape[2], axis=-1)\n",
    "    return scaler.inverse_transform(np.reshape(predictions_copies, (len(predictions), shape[2])))[:, 0]\n",
    "\n",
    "# stacked_pred = inverse_transform_and_reshape(stacked_test_predictions, scaler, trainX.shape)\n",
    "\n",
    "# # Original test label\n",
    "# original_copies_array = np.repeat(testY, trainX.shape[2], axis=-1)\n",
    "# original_testY = scaler.inverse_transform(np.reshape(original_copies_array, (len(testY), trainX.shape[2])))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "  build_model,\n",
    "  objective=\"mse\",\n",
    "  max_trials=10,\n",
    "  executions_per_trial=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testX.shape)\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x=trainX, y=trainY, epochs=20, batch_size=128, validation_data=(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(trainX, trainY, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = best_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_pred = inverse_transform_and_reshape(test_predictions, scaler, trainX.shape)\n",
    "\n",
    "# Original test label\n",
    "original_copies_array = np.repeat(testY, trainX.shape[2], axis=-1)\n",
    "original_testY = scaler.inverse_transform(np.reshape(original_copies_array, (len(testY), trainX.shape[2])))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stacked Model:\")\n",
    "mse = mean_squared_error(original_testY, stacked_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "rmse = sqrt(mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Stacked Model\n",
    "plt.plot(original_testY[0:100], label='Actual')\n",
    "plt.plot(stacked_pred[0:100], label='Stacked Model Predicted')\n",
    "plt.xlabel('Time')  # Use `xlabel` instead of `set_xlabel`\n",
    "plt.ylabel('Passengers')\n",
    "plt.legend()\n",
    "plt.title('Actual vs. Stacked Model Predicted Passengers')  # Use `title` instead of `set_title`\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
